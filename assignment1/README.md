# Assignment 1

## kNN Classifier

- Easy warm-up
- CIFAR-10 data
- Cross-validation

## SVM Classifier

- Linear SVM analytical gradient computation
- Stochastic Gradient Descent (GSD) optimization
- Tuning learning rate
- Regularization
- Loss function
- Numerical gradient check

## Softmax

- Vectorized loss function for the Softmax classifier
- Its analytic gradient

## Two-layer Neural Net

- Two-layer fully connected network
- Forward pass: scores and loss
- Backward pass: gradient of the loss
- Experimentation / fine tuning the hyperparameters
  - One observation: when selectively starting with the weights from a
    previous trial, one can achieve better results in the long term;
    these weights can be slightly randomized as well.
